})
}
server = function(input, output) {
output$selected_var <- renderText({
paste("You have selected", input$var)
})
output$selected_range = renderText({
paste("for the range", input$range)
})
}
shinyApp(ui = ui, server = server)
server <- function(input, output) {
output$selected_var <- renderText({
paste("You have selected", input$var)
})
output$selected_range = renderText({
paste("for the range", input$range)
})
}
shinyApp(ui = ui, server = server)
runApp("census-app", display.mode = "showcase")
ui <- fluidPage(
titlePanel("censusVis"),
sidebarLayout(
sidebarPanel(
helpText("Create demographic maps with
information from the 2010 US Census."),
selectInput("var",
label = "Choose a variable to display",
choices = c("Percent White",
"Percent Black",
"Percent Hispanic",
"Percent Asian"),
selected = "Percent White"),
sliderInput("range",
label = "Range of interest:",
min = 0, max = 100, value = c(0, 100))
),
mainPanel(
textOutput("selected_var"),
textOutput("selected_range")
)
)
)
server = function(input, output) {
output$selected_var <- renderText({
paste("You have selected", input$var)
})
output$selected_range = renderText({
paste("for the range", input$range)
})
}
shinyApp(ui = ui, server = server)
# Note: percent map is designed to work with the counties data set
# It may not work correctly with other data sets if their row order does
# not exactly match the order in which the maps package plots counties
percent_map <- function(var, color, legend.title, min = 0, max = 100) {
# generate vector of fill colors for map
shades <- colorRampPalette(c("white", color))(100)
# constrain gradient to percents that occur between min and max
var <- pmax(var, min)
var <- pmin(var, max)
percents <- as.integer(cut(var, 100,
include.lowest = TRUE, ordered = TRUE))
fills <- shades[percents]
# plot choropleth map
map("county", fill = TRUE, col = fills,
resolution = 0, lty = 0, projection = "polyconic",
myborder = 0, mar = c(0,0,0,0))
# overlay state borders
map("state", col = "white", fill = FALSE, add = TRUE,
lty = 1, lwd = 1, projection = "polyconic",
myborder = 0, mar = c(0,0,0,0))
# add a legend
inc <- (max - min) / 4
legend.text <- c(paste0(min, " % or less"),
paste0(min + inc, " %"),
paste0(min + 2 * inc, " %"),
paste0(min + 3 * inc, " %"),
paste0(max, " % or more"))
legend("bottomleft",
legend = legend.text,
fill = shades[c(1, 25, 50, 75, 100)],
title = legend.title)
}
library(maps)
library(mapproj)
source("census-app/helpers.R")
counties <- readRDS("census-app/data/counties.rds")
percent_map(counties$white, "darkgreen", "% White")
runApp('census-app')
library(maps)
library(mapproj)
library(shiny)
source("helpers.R")
counties <- readRDS("data/counties.rds")
# User Interface
ui <- fluidPage(
titlePanel("censusVis"),
sidebarLayout(
sidebarPanel(
helpText("Create demographic maps with
information from the 2010 US Census."),
selectInput("var",
label = "Choose a variable to display",
choices = c("Percent White",
"Percent Black",
"Percent Hispanic",
"Percent Asian"),
selected = "Percent White"),
sliderInput("range",
label = "Range of interest:",
min = 0, max = 100, value = c(0, 100))
),
mainPanel(
textOutput("selected_var"),
textOutput("selected_range")
)
)
)
# Server Logic
server = function(input, output) {
output$map = renderPlot({
data = switch(input$var,
"Percent White" = counties$white,
"Percent Black" = counties$black,
"Percent Hispanic" = counties$hispanic,
"Percent Asian" = counties$asian)
color = switch(input$var,
"Percent White" = "darkgreen",
"Percent Black" = "black",
"Percent Hispanic" = "darkorange",
"Percent Asian" = "darkviolet")
legend = switch(input$var,
"Percent White" = "% White",
"Percent Black" = "% Black",
"Percent Hispanic" = "% Hispanic",
"Percent Asian" = "% Asian")
percent_map(data, color, legend, input$range[1], input$range[2])
})
output$selected_var <- renderText({
paste("You have selected", input$var)
})
output$selected_range = renderText({
paste("for the range", input$range)
})
}
shinyApp(ui = ui, server = server)
runApp("census-app", display.mode = "showcase")
library(maps)
library(mapproj)
library(shiny)
source("helpers.R")
counties <- readRDS("data/counties.rds")
# User Interface
ui <- fluidPage(
titlePanel("censusVis"),
sidebarLayout(
sidebarPanel(
helpText("Create demographic maps with
information from the 2010 US Census."),
selectInput("var",
label = "Choose a variable to display",
choices = c("Percent White",
"Percent Black",
"Percent Hispanic",
"Percent Asian"),
selected = "Percent White"),
sliderInput("range",
label = "Range of interest:",
min = 0, max = 100, value = c(0, 100))
),
mainPanel(
textOutput("selected_var"),
textOutput("selected_range")
)
)
)
# Server Logic
server = function(input, output) {
output$map = renderPlot({
data = switch(input$var,
"Percent White" = counties$white,
"Percent Black" = counties$black,
"Percent Hispanic" = counties$hispanic,
"Percent Asian" = counties$asian)
color = switch(input$var,
"Percent White" = "darkgreen",
"Percent Black" = "black",
"Percent Hispanic" = "darkorange",
"Percent Asian" = "darkviolet")
legend = switch(input$var,
"Percent White" = "% White",
"Percent Black" = "% Black",
"Percent Hispanic" = "% Hispanic",
"Percent Asian" = "% Asian")
percent_map(data, color, legend, input$range[1], input$range[2])
})
}
shinyApp(ui = ui, server = server)
source("helpers.R")
counties <- readRDS("data/counties.rds")
# User Interface
ui <- fluidPage(
titlePanel("censusVis"),
sidebarLayout(
sidebarPanel(
helpText("Create demographic maps with
information from the 2010 US Census."),
selectInput("var",
label = "Choose a variable to display",
choices = c("Percent White",
"Percent Black",
"Percent Hispanic",
"Percent Asian"),
selected = "Percent White"),
sliderInput("range",
label = "Range of interest:",
min = 0, max = 100, value = c(0, 100))
),
mainPanel(plotOutput("map"))
)
)
# Server Logic
server = function(input, output) {
output$map = renderPlot({
data = switch(input$var,
"Percent White" = counties$white,
"Percent Black" = counties$black,
"Percent Hispanic" = counties$hispanic,
"Percent Asian" = counties$asian)
color = switch(input$var,
"Percent White" = "darkgreen",
"Percent Black" = "black",
"Percent Hispanic" = "darkorange",
"Percent Asian" = "darkviolet")
legend = switch(input$var,
"Percent White" = "% White",
"Percent Black" = "% Black",
"Percent Hispanic" = "% Hispanic",
"Percent Asian" = "% Asian")
percent_map(data, color, legend, input$range[1], input$range[2])
})
}
shinyApp(ui = ui, server = server)
runGitHub("census-app", "cabolz")
runGitHub("STAT433-HW/census-app", "cabolz")
runGitHub(repo = "STAT433-HW", username = "cabolz", subdir = "census-app")
runGitHub(repo = "STAT433-HW", username = "cabolz", subdir = "census-app")
runGitHub(repo = "STAT433-HW", username = "cabolz")
# library(rARPACK)
install.packages("glmnet")
library(data.table)
library(tidyverse)
library(tidytext)
library(Matrix)
library(rARPACK)
library(glmnet)
library(randomForest)
data = fread("https://raw.githubusercontent.com/bpb27/political_twitter_archive/master/realdonaldtrump/realdonaldtrump.csv") %>% as.tbl
str(data)
text_df <- tibble(tweet = 1:nrow(data), text = data$text)
View(text_df)
# this does a lot of processing!
#  to lower, remove @ # , .
#  often these make sense on a first cut.
#  worth revisiting before "final results"!
tt  = text_df %>% unnest_tokens(word, text)
str(tt)
View(tt)
# make the document-term matrix.
#   I sometimes call this the bag-of-words-matrix.
dt = cast_sparse(tt, tweet, word)
dt[1:5,1:10]
str(dt)
dim(dt)
hist(rowSums(dt))
dt[1:10,1:20]
cs = colSums(dt)
hist(log(cs[cs>1]))
# can we predict which phone it came from?
# http://varianceexplained.org/r/trump-tweets/
table(data$source) %>% sort
# these are tweets that we think trump wrote himself:
y = data$source == "Twitter for Android"
sum(cs>20)
x = dt[,cs>20]  # is it "cheating" to select variables with cs?
dim(x)  # what do we do???
# fancy regression!
fit = glmnet(x,
y ,
family = "binomial",
alpha  = .9)
dim(x)  # should have 2286 betas...
coef(fit) %>% dim  # but we actually have 100 of those beta vectors!
# fancy regression!
fit = glmnet(x,
y ,
family = "binomial",
alpha  = .9,
standardize = F)
dim(x)  # should have 2286 betas...
coef(fit) %>% dim  # but we actually have 100 of those beta vectors!
dim(df)
dim(dt)
tt$word %>% unique %>% length
cvfit = cv.glmnet(x,y,
family = "binomial",
type.measure = "class",
nfolds = 5,
alpha = .1,
)
plot(cvfit)
betaHat = coef(cvfit, s = "lambda.1se")
betaHat = coef(cvfit, s = "lambda.1se")
tibble(word = colnames(x), beta = as.vector(betaHat[-1])) %>% arrange(-beta)
tibble(word = colnames(x), beta = as.vector(betaHat[-1])) %>% arrange(beta)
library(data.table)
library(tidyverse)
library(tidytext)
library(Matrix)
library(rARPACK)
library(glmnet)
library(randomForest)
data = fread("https://raw.githubusercontent.com/bpb27/political_twitter_archive/master/realdonaldtrump/realdonaldtrump.csv") %>% as.tbl
text_df <- tibble(tweet = 1:nrow(data), text = data$text)
# this does a lot of processing!
#  to lower, remove @ # , .
#  often these make sense on a first cut.
#  worth revisiting before "final results"!
tt  = text_df %>% unnest_tokens(word, text)
# make the document-term matrix.
#   I sometimes call this the bag-of-words-matrix.
dt = cast_sparse(tt, tweet, word)
dt[1:10,1:20]
cs = colSums(dt)
# can we predict which phone it came from?
# http://varianceexplained.org/r/trump-tweets/
table(data$source) %>% sort
# these are tweets that we think trump wrote himself:
y = data$source == "Twitter for Android"
sum(cs>20)
x = dt[,cs>20]  # is it "cheating" to select variables with cs?
dim(x)  # what do we do???
# fancy regression!
fit = glmnet(x,
y ,
family = "binomial",
alpha  = .9,
standardize = F)
dim(x)  # should have 2286 betas...
coef(fit) %>% dim  # but we actually have 100 of those beta vectors!
cvfit = cv.glmnet(x,y,
family = "binomial",
type.measure = "class",
nfolds = 5,
alpha = .1,
)
plot(cvfit)
betaHat = coef(cvfit, s = "lambda.1se")
tibble(word = colnames(x), beta = as.vector(betaHat[-1])) %>% arrange(-beta)
tibble(word = colnames(x), beta = as.vector(betaHat[-1])) %>% arrange(beta)
# sentiment analysis!
#   http://tidytextmining.com/sentiment.html
#   sentiment analysis is a way of creating new features from words.
#   words are assigned values, eg whether they belong to these types:
sentiments$sentiment %>% table %>% names
str(sentiments)
install.packages("textdata")
library(textdata)
get_sentiments("afinn")$value %>% table
finnFeat = tt %>%
left_join(get_sentiments("afinn")) %>%
group_by(tweet) %>%
summarize(afinn = mean(value, na.rm = T),
afinnWords = sum(!is.na(value))
)
bing = get_sentiments("bing") %>% mutate(neg= sentiment == "negative", pos = sentiment =="positive")
bingFeat = tt %>%
left_join(bing) %>%
group_by(tweet) %>%
summarize(bingNeg = sum(neg, na.rm = T),
bingPos = sum(pos, na.rm = T),
bingWords = bingNeg + bingPos,
bing = bingPos/bingWords)
lough = get_sentiments("loughran") %>% rename(lough = sentiment)
finnFeat = tt %>%
left_join(get_sentiments("afinn")) %>%
group_by(tweet) %>%
summarize(afinn = mean(value, na.rm = T),
afinnWords = sum(!is.na(value))
)
bing = get_sentiments("bing") %>% mutate(neg= sentiment == "negative", pos = sentiment =="positive")
bingFeat = tt %>%
left_join(bing) %>%
group_by(tweet) %>%
summarize(bingNeg = sum(neg, na.rm = T),
bingPos = sum(pos, na.rm = T),
bingWords = bingNeg + bingPos,
bing = bingPos/bingWords)
lough = get_sentiments("loughran") %>% rename(lough = sentiment)
lough = lough %>% mutate(value = 1) %>% pivot_wider(word, names_from = lough)
loughFeat = tt %>%
left_join(lough) %>%
group_by(tweet) %>%
summarize(  # is there an easier way to do this...???
loughneg = sum(negative, na.rm=T),
loughpos = sum(positive, na.rm=T),
loughUnc = sum(uncertainty, na.rm=T),
loughlit = sum(litigious, na.rm=T),
loughConst = sum(constraining, na.rm=T),
loughsuperfluous = sum(superfluous, na.rm=T))
xsent = finnFeat %>% left_join(bingFeat) %>% left_join(loughFeat)
xsent[is.na(xsent)] = 0
#make sure rows are in order:
mean(xsent$tweet == 1:nrow(xsent))
str(xsent)
fit = glm(y~ . -tweet, family = "binomial", data = xsent)
summary(fit)  # whats up with bingwords???
fit = glm(y~ . - tweet - bingNeg - bingPos, family = "binomial", data = xsent)
summary(fit)
cvfit = cv.glmnet(as.matrix(xsent),y,
family = "binomial",
type.measure = "class",
nfolds = 5,
alpha = .1)
plot(cvfit)
get_sentiments("nrc") %>%
pivot_wider(word, names_from = sentiments)
nrc %>%
mutate(value = 1) %>%
pivot_wider(word, names_from = nrc)
get_sentiments("nrc") %>%
pivot_wider(word, names_from = sentiments)
nrc = get_sentiments("nrc") %>% rename(nrc = sentiment)
nrc %>%
mutate(value = 1) %>%
pivot_wider(word, names_from = nrc)
get_sentiments("nrc") %>%
pivot_wider(word, names_from = sentiments)
bingFeat = tt %>%
left_join(bing) %>%
group_by(tweet) %>%
summarize(bingNeg = sum(neg, na.rm = T),
bingPos = sum(pos, na.rm = T),
bingWords = bingNeg + bingPos,
bing = bingPos/(bingWords+.000001))
nrcFeat = tt %>%
left_join(nrcWide) %>%
group_by(tweet) %>%
summarise(
nrcTrust = sum(trust, na.rm = T),
nrcFear = sum(fear, na.rm = T),
nrcNegative = sum(negative, na.rm = T),
nrcSadness = sum(sadness, na.rm = T),
nrcAnger = sum(anger, na.rm = T),
nrcSurprise = sum(surprise, na.rm = T),
nrcPositive = sum(positive, na.rm = T),
nrcDisgust = sum(disgust, na.rm = T),
nrcJoy = sum(joy, na.rm = T),
nrcAnticipation = sum(anticipation, na.rm = T),
)
nrcWide = nrc %>%
mutate(value = 1) %>% pivot_wider(word, names_from = nrc)
nrcFeat = tt %>%
left_join(nrcWide) %>%
group_by(tweet) %>%
summarise(
nrcTrust = sum(trust, na.rm = T),
nrcFear = sum(fear, na.rm = T),
nrcNegative = sum(negative, na.rm = T),
nrcSadness = sum(sadness, na.rm = T),
nrcAnger = sum(anger, na.rm = T),
nrcSurprise = sum(surprise, na.rm = T),
nrcPositive = sum(positive, na.rm = T),
nrcDisgust = sum(disgust, na.rm = T),
nrcJoy = sum(joy, na.rm = T),
nrcAnticipation = sum(anticipation, na.rm = T),
)
xsent = finnFeat %>% left_join(bingFeat) %>% left_join(loughFeat)
xsent[is.na(xsent)] = 0
#make sure rows are in order:
mean(xsent$tweet == 1:nrow(xsent))
str(xsent)
fit = glm(y~ . -tweet, family = "binomial", data = xsent)
summary(fit)  # whats up with bingwords???
fit = glm(y~ . -tweet, family = "binomial", data = nrcFeat)
summary(fit)  # whats up with bingwords???
xsent = finnFeat %>% left_join(bingFeat) %>% left_join(loughFeat) %>% left_join(nrcFeat)
xsent[is.na(xsent)] = 0
#make sure rows are in order:
mean(xsent$tweet == 1:nrow(xsent))
str(xsent)
fit = glm(y~ . -tweet, family = "binomial", data = xsent)
summary(fit)  # whats up with bingwords???
fit = glm(y~ . - tweet - bingNeg - bingPos, family = "binomial", data = xsent)
summary(fit)
cvfit = cv.glmnet(as.matrix(xsent),y,
family = "binomial",
type.measure = "class",
nfolds = 5,
alpha = .1)
plot(cvfit)
xsentRescaled = scale(xsent)
apply(xsent[,-1], 2, sd) %>% plot
apply(xsentRescaled[,-1], 2, sd) %>% plot
.5*sqrt(6)
sqrt(6)
sqrt(6)*.5
4-.5-.5*6
4-.5-(.5*6)
(4-.5-(.5*6))/(sqrt(6)*.5)
